---
layout: post
title:  Hadoop1.2.1本地伪分布式安装
description: "Hadoop1.2.1本地伪分布式安装"
category: project
avatarimg: "/img/touxiang.png"
tags : [apue,Hadoop]
duoshuo: true
---
##引言
由于最近需要大数据的处理，所以需要用到hadoop.因此在这里记录本地伪分布式的安装过程。

<!-- more -->

##下载jdk以及配置环境变量
这里采用jdk1.6 将其拷贝到/usr/jdk下面，执行安装文件后。然后需要配置JAVA_HOME和CLASSPATH.    
使用vim 进入/etc/profile.在结尾部分添加如下内容：

	JAVA_HOME=/usr/java/jdk1.6.0_45
	PATH=$JAVA_HOME/bin:$PATH
	CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
	export JAVA_HOME PATH CLASSPATH

保存后，执行以下命令使配置文件生效

	source /etc/profile

检查java是否安装成功

	java -version

##安装hadoop
这里使用hadoop1.2.1，解压到/usr/hadoop1.2.1中。   
然后配置SSH

	1.生成秘钥
	ssh-keygen -t rsa
	2.一直回车即可,然后进入.ssh目录,执行命令
	cd ~/.ssh
	cp id_rsa.pub authorized_keys
	3.检查是否需要密码
	ssh localhost

进入hadoop安装路径，对hadoop进行配置。
##配置hadoop
配置core-site.xml:   
vi core-site.xml打开core-site.xml文件，然后在configuration标签中加入以下内容：

	<property>
	
	<name>fs.default.name</name> 
	
	<value>hdfs://localhost:9000</value>
	
	</propety>
	
	<!—fs.default.name：用来配置namenode,指定HDFS文件系统的URL，通过该URL我们可以访问文件系统的内容，也可以把localhost换成本机IP地址；如果是完全分布模式，则必须把localhost改为实际namenode机器的IP地址；如果不写端口，则使用默认端口8020。 -->
	
	<property>
	
	<name>hadoop.tmp.dir</name>
	
	<value>/tmp/hadoop/hadoop_tmp</value>
	
	</property>
	
	<!-- hadoop.tmp.dir：Hadoop的默认临时路径，这个最好配置，如果在新增节点或者其他情况下莫名其妙的DataNode启动不了，就删除此文件中的tmp目录即可。不过如果删除了NameNode机器的此目录，那么就需要重新执行NameNode格式化的命令。该目录必须预先手工创建。-->

配置hdfs-site.xml:   
在configuration标签中加入以下内容，所有不存在的目录都要预先创建：
	
	<property>
	
	<name>dfs.data.dir</name>   
	
	<value>/home/hadoop/hadoop_dir/dfs/data</value>
	
	</property>
	
	<!--配置HDFS存储目录,数据存放目录,用于datanode存放数据-->
	
	<property>
	
	<name>dfs.name.dir</name>
	
	<value>/home/hadoop/hadoop_dir/dfs/name</value>
	
	</property>
	
	<!—用来存储namenode的文件系统元数据，包括编辑日志和文件系统映像，如果更换地址的话，则需要重新使用hadoop namenode –format命令格式化namenode-->
	
	<property>
	
	<name>dfs.replication</name>
	
	<value>1</value> 
	
	</proerty>
	
	<!—用来设置文件系统冗余备份数量，因为只有一个节点，所有设置为1，系统默认数量为3-->

配置mapred-site.xml:   
在configuration标签中加入以下内容：

	<property>
	
	<name>mapred.job.tracker</name>
	
	<value>localhost:9001</value>     
	
	</property>
	
	<!—该项配置用来配置jobtracker节点，localhost也可以换成本机的IP地址；真实分布模式下注意更改成实际jobtracker机器的IP地址-->

##运行hadoop
####1.格式化HDFS文件
	
	bin/hadoop namenode -format

这里有可能会报“主机找不到错误”，此时需要查看主机名是否有问题，详情见[主机找不到处理][1]

####2.启动hadoop环境
	
	bin/start-all.sh

####3.查看是否启动完全
	
	jps

查看是否成功启动SecondaryNamenode，JobTracker，NameNode，DataNode，TraskTracker五个进程，而刚好这五个进程是hadoop所需要的。如果有一个进程没有启动成功，就表示整个集群没有正常工作，我们可以进入/data/software/hadoop/hadoop-1.2.1/libexec/../logs/目录下查看失败日记

####4.从浏览器查看hadoop信息:
我们可以从本机或者其他机器的浏览器访问hadoop。（**ip地址自己修改成自己的**）

查看jobtracker信息：

http://192.168.0.107:50030/jobtracker.jsp

查看namenode信息：

http://192.168.0.107:50070/dfshealth.jsp

查看trasktracker信息：

http://192.168.0.107:50060/tasktracker.jsp


##WordCount测试
1.我们创建一个input文件夹，并且创建3个文件，给每个文件写一些内容：

	mkdir input
	
	echo “hello hadoop” >input/f1.txt
	
	echo “hello word” >input/f2.txt
	
	echo “hello java” >input/f3.txt

2.使用以下命令在hadoop中创建文件夹：

	bin/hadoop fs –mkdir input

3.我们查看在hadoop中是否已经创建该文件夹：

	bin/hadoop fs –ls /user/root

4.使用以下命令把文件从Linux中复制到hadoop中：

	bin/hadoop fs –put input/* input

5.查看文件是否在hadoop中：

	bin/hadoop fs –ls input

6.查看文件内容是否一致：

	bin/hadoop fs –cat input/f1.txt

7.执行wordcount示例程序

	bin/hadoop jar hadoop-examples-1.2.1.jar wordcount /user/root/input /user/root/output (注：这里的root为hadoop运行时的用户名，根据需要换成自己的实际用户名)

8.从hdfs中取回文件到本地

	bin/hadoop fs -get /user/root/output /root (这样，就把运算结果output中的文件放到本地root目录下了)

[1]:http://blog.csdn.net/shirdrn/article/details/6562292