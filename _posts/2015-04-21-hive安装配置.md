---
layout: post
title:   Hive 安装配置
description: " Hive 安装配置"
category: project
avatarimg: "/img/touxiang.jpg"
tags : [Hadoop,Hive]
duoshuo: true
---
主要对hive的安装进行配置。
<!-- more -->

##二、Hive 运行模式

与 Hadoop 类似，Hive 也有 3 种运行模式：

&gt; **1. 内嵌模式**
&gt; 
将元数据保存在本地内嵌的 Derby 数据库中，这是使用 Hive 最简单的方式。但是这种方式缺点也比较明显，因为一个内嵌的 Derby 数据库每次只能访问一个数据文件，这也就意味着它不支持多会话连接。

&gt; **2. 本地模式**
&gt; 
这种模式是将元数据保存在本地独立的数据库中（一般是 MySQL），这用就可以支持多会话和多用户连接了。

&gt; **3. 远程模式**
&gt; 
此模式应用于 Hive 客户端较多的情况。把 MySQL 数据库独立出来，将元数据保存在远端独立的 MySQL 服务中，避免了在每个客户端都安装 MySQL 服务从而造成冗余浪费的情况。


## 三、下载安装 Hive

上节课程我们已经了解到，Hive 是基于 Hadoop 文件系统之上的数据仓库。因此，安装Hive之前必须确保 Hadoop 已经成功安装。（本次实验环境，已经为大家安装好了 Hadoop.）
 
本次实验，使用Hive V1.1.0版本。Hive V1.1.0 可以在 Hadoop V1.0.0 以上环境中工作。终端下输入命令来下载：

	$ wget http://labfile.oss.aliyuncs.com/apache-hive-1.1.0-bin.tar.gz


下载完成后解压：


	$ tar zxvf apache-hive-1.1.0-bin.tar.gz


解压出来的文件名很长，在终端下输入很麻烦，为了后面实验的方便，建议修改为较短文件名，例如：


	$ mv apache-hive-1.1.0-bin hive


## 四、配置系统环境变量

修改 /etc/profile 文件，这个我们在 Hadoop 和 [HBase 的课程](http://www.shiyanlou.com/courses/37) 中也修改过，应该比较熟悉了。在 PATH 中加入 Hive 的 bin 以及 conf 路径（请根据自己的实际路径修改），使用 `sudo vim /etc/profile` 来修改：


	# Hive environment
	export HIVE_HOME=/usr/local/hadoop/hive
	export PATH=$HIVE_HOME/bin:$HIVE_HOME/conf:$PATH




## 五、内嵌模式

**（1）修改 Hive 配置文件**

$HIVE_HOME/conf 对应的是 Hive 的配置文件路径，类似于之前学习的HBase, 该路径下的 hive-site.xml 是 Hive 工程的配置文件。默认情况下，该文件并不存在，我们需要拷贝它的模版来实现：


	$ cp hive-default.xml.template hive-site.xml


hive-site.xml 的主要配置有：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427423801808)

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427423813828)

&gt; * **hive.metastore.warehouse.dir**
&gt; 该参数指定了 Hive 的数据存储目录，默认位置在 HDFS 上面的 /user/hive/warehouse 路径下。

&gt; * **hive.exec.scratchdir**
&gt; 该参数指定了 Hive 的数据临时文件目录，默认位置为 HDFS 上面的 /tmp/hive 路径下。

同时我们还要修改 Hive 目录下 /conf/hive-env.sh 文件（请根据自己的实际路径修改），该文件默认也不存在，同样是拷贝它的模版来修改：


	export HADOOP_HEAPSIZE=1024
	
	# Set HADOOP_HOME to point to a specific hadoop install directory
	HADOOP_HOME=/usr/local/hadoop
	
	# Hive Configuration Directory can be controlled by:
	export HIVE_CONF_DIR=/usr/local/hadoop/hive/conf
	
	# Folder containing extra ibraries required for hive compilation/execution can be controlled by:
	export HIVE_AUX_JARS_PATH=/usr/local/hadoop/hive/lib


**（2）创建必要目录**

前面我们看到 hive-site.xml 文件中有两个重要的路径，切换到 hadoop 用户下查看 HDFS 是否有这些路径：


	$ hadoop dfs -ls /


![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424044890)

没有发现上面提到的路径，因此我们需要自己新建这些目录，并且给它们赋予用户写（W）权限。


	$ hadoop dfs -mkdir /user/hive/warehouse
	$ hadoop dfs -mkdir /tmp/hive
	$ hadoop dfs -chmod 777 /user/hive/warehouse
	$ hadoop dfs -chmod 777 /tmp/hive


如果你遇到  `no such file or directory` 类似的错误，就一步一步新建目录，例如：


	$ hadoop dfs -mkdir /tmp
	$ hadoop dfs -mkdir /tmp/hive


检查是否新建成功 `hadoop dfs -ls /` 以及 `hadoop dfs -ls /user/hive/` ：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424512161)

**（3）修改 io.tmpdir 路径**

同时，要修改 hive-site.xml 中所有包含 `${system:java.io.tmpdir}` 字段的 value 即路径（vim下 / 表示搜索，后面跟你的关键词，比如搜索 hello，则为 `/hello` , 再回车即可），你可以自己新建一个目录来替换它，例如 `/home/hive/iotmp` . 同样注意修改写权限。如果不修改这个，你很可能会出现如下错误：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424529728)


**（4）运行 Hive**

前面我们已经提到过，内嵌模式使用默认配置和 Derby 数据库，所以无需其它特别修改，先 `./start-all.sh` 启动 Hadoop,  然后直接运行 `hive`：

**你很可能会遇到这个错误：**

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424670386)

这是因为 Hive 中的 Jline jar 包和 Hadoop 中的 Jline 冲突了，在路径：$HADOOP_HOME/share/hadoop/yarn/lib/jline-0.9.94.jar 将其删除。

再次启动 `hive`，就OK了:

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424712845)

`show tables;` 注意不要漏写了 **分号**。

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427424740729)


## 六、本地模式

现在我们替换默认的 Derby 数据库为 MySQL数据库。

**（1）下载安装 MySQL**


	$ sudo apt-get install mysql-server


本实验环境下默认是安装了 MySQL 的，直接启动它：


	$ sudo service mysql start


添加 root 用户，创建 hive 数据库：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427425205044)

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427425375983)

虽然 MySQL 已经默认安装，但我们还需要下载一个 MySQL 的 JDBC 驱动包。这里使用的是 `mysql-connector-java-5.1.35-bin.jar`，你需要将其复制到  $HIVE_HOME/lib 目录下面：


	$ wget http://labfile.oss.aliyuncs.com/mysql-connector-java-5.1.35.tar.gz
	
	$ tar zxvf mysql-connector-java-5.1.35.tar.gz
	
	$ cd mysql-connector-java-5.1.35
	
	$ mv mysql-connector-java-5.1.35-bin.jar /usr/local/hadoop/hive/lib/


**（2）修改 hive-site.xml 配置文件**

最后，依然是修改 $HIVE_HOME/conf 下的 hive-site.xml 文件，把默认的 Derby 修改为 MySQL : 


&lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    //所连接的MySQL数据库实例
    &lt;value&gt;jdbc:mysql://localhost:3306/hive&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
	&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
    //连接的MySQL数据库驱动
    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
    //连接的MySQL数据库用户名
    &lt;value&gt;hive&lt;/value&gt;
&lt;/property&gt;
 
&lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    //连接的MySQL数据库密码
    &lt;value&gt;hive&lt;/value&gt;
&lt;/property&gt;


**（3）启动 Hive**

启动 Hive 的方式同内嵌模式一样：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid766time1427425424217)