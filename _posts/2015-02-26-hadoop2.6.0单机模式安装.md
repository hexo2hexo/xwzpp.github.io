---
layout: post
title:  Hadoop2.6.0单机版模式安装
description: "Hadoop2.6.0单机模式安装"
category: project
avatarimg: "/img/touxiang.jpg"
tags : [apue,Hadoop]
duoshuo: true
---

##一、Hadoop启动模式

Hadoop集群有三种启动模式：

+ 单机模式：默认情况下运行为一个单独机器上的独立Java进程，主要用于调试环境
+ 伪分布模式：在单个机器上模拟成分布式多节点环境，每一个Hadoop守护进程都作为一个独立的Java进程运行
+ 完全分布式模式：真实的生产环境，搭建在完全分布式的集群环境

<!-- more -->

##二、用户及用户组

需要先添加用来运行Hadoop进程的用户组hadoop及用户hadoop。

###1. 添加用户及用户组

创建用户hadoop

	$ sudo adduser hadoop

并按照提示输入hadoop用户的密码。

###2. 添加sudo权限

将hadoop用户添加进sudo用户组

	$ sudo usermod -G sudo hadoop

##三、安装及配置依赖的软件包


###1. 安装openssh-server、java、rsync等


	$ sudo apt-get update
	$ sudo apt-get install openssh-server rsync
	$ sudo service ssh restart
	$ sudo apt-get install openjdk-7-jdk
	$ java -version


###2. 配置ssh免密码登录

切换到hadoop用户，需要输入添加hadoop用户时配置的密码。后续步骤都将在hadoop用户的环境中执行。


	$ su -l hadoop


配置ssh环境免密码登录。


	$ ssh-keygen -t rsa -P "";


在/home/hadoop/.ssh目录下生成了id_rsa（私钥）和id_rsa.pub（公交两个文件）,将公钥追加到authorized_keys中，该文件保存所有允许以当前用户身份登录到ssh客户端用户的公钥内容。


	$ cat ~/.ssh/id_rsa.pub >>; ~/.ssh/authorized_keys


验证登录本机是否还需要密码，配置正确的话是可以不需密码登录的。

	$ ssh localhost


##四、下载并安装Hadoop

在hadoop用户登录的环境中进行下列操作：

###1. 下载Hadoop 2.6.0


	$ wget http://mirrors.aliyuncs.com/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz


###2. 解压并安装


	$ tar zxvf hadoop-2.6.0.tar.gz
	$ sudo mv hadoop-2.6.0 /usr/local/hadoop
	$ sudo chmod 774 /usr/local/hadoop


###3. 配置Hadoop

	$ vim /home/hadoop/.bashrc


在/home/hadoop/.bashrc文件末尾添加下列内容：


	#HADOOP START
	export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
	export HADOOP_INSTALL=/usr/local/hadoop
	export PATH=$PATH:$HADOOP_INSTALL/bin
	export PATH=$PATH:$HADOOP_INSTALL/sbin
	export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
	export HADOOP_COMMON_HOME=$HADOOP_INSTALL
	export HADOOP_HDFS_HOME=$HADOOP_INSTALL
	export YARN_HOME=$HADOOP_INSTALL
	export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
	export HADOOP_OPTS=&#34;-Djava.library.path=$HADOOP_INSTALL/lib&#34;
	#HADOOP END


保存退出后，激活新加的环境变量

	$ source ~/.bashrc


至此，Hadoop单机模式安装完成，可以通过下述步骤的测试来验证安装是否成功。

##五、测试验证

创建输入的数据，暂时采用/etc/protocols文件作为测试


	$ cd /usr/local/hadoop
	$ sudo mkdir input
	$ sudo cp /etc/protocols ./input


执行Hadoop WordCount应用（词频统计）

	$ bin/hadoop jar share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.6.0-sources.jar org.apache.hadoop.examples.WordCount input output


查看生成的单词统计数据


	$ cat output/*
